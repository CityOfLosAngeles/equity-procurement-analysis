{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAICS Code Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes the complete code of how to re-generate the `Getting NAICS Codes w/o Proprietary Departments` NAICS codes analysis sheet. Determines NAICS codes used by the city, number of opportunities, DBE/MBE/WBE breakdowns, and category breakdowns all by each NAICS code used by # of opp. frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By: Calvin Chen and Irene Tang**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import collections\n",
    "import json\n",
    "import itertools\n",
    "import re\n",
    "import pygsheets\n",
    "# from utils import get_arcgis_access_token, get_credentials, refresh_access_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_http(ep):\n",
    "    \"\"\"\n",
    "    Gets the initial http domain for HTTP requests.\n",
    "    \"\"\"\n",
    "    return 'https://lacity.my.salesforce.com' + ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soql_to_python(soql_statement):\n",
    "    \"\"\"\n",
    "    Converts a SOQL query into its Python-form for making a request.\n",
    "    \"\"\"\n",
    "    return '+'.join(soql_statement.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_to_soql(python_statement):\n",
    "    \"\"\"\n",
    "    Converts a Python SOQL query back into its SOQL form.\n",
    "    \"\"\"\n",
    "    return ' '.join(python_statement.split('+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_endpoint(query):\n",
    "    \"\"\"\n",
    "    Generates the endpoint for Salesforce given the passed in SOQL query.\n",
    "    \"\"\"\n",
    "    return '/services/data/v51.0/query/?q=' + query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_simple_request(endpoint, full_url=True):\n",
    "    \"\"\"\n",
    "    Makes the request to Salesforce for the given endpoint.\n",
    "    \"\"\"\n",
    "    payload={}\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json',\n",
    "      'Authorization': 'Bearer ***REMOVED***',\n",
    "      'Cookie': 'BrowserId=IoTFrthNEeuXEXtWwwGMWA; CookieConsentPolicy=0:0'\n",
    "    }\n",
    "\n",
    "    # Making the request\n",
    "    url = endpoint if full_url else get_http(endpoint)\n",
    "    res = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    return res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_a_key(d: dict, remove_key: str) -> dict:\n",
    "    \"\"\"\n",
    "    Removes a key passed in as `remove_key` from a dictionary `d`.\n",
    "    Reference: https://stackoverflow.com/questions/58938576/remove-key-and-its-value-in-nested-dictionary-using-python\n",
    "    \"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        for key in list(d.keys()):\n",
    "            if key == remove_key:\n",
    "                del d[key]\n",
    "            else:\n",
    "                remove_a_key(d[key], remove_key)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d, parent_key='', sep='.'):\n",
    "    \"\"\"\n",
    "    Flattens a dictionary.\n",
    "    Source: https://stackoverflow.com/questions/6027558/flatten-nested-dictionaries-compressing-keys\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_credentials(filename):\n",
    "    \"\"\"\n",
    "    Getting credentials from given file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        credentials = json.load(f)\n",
    "        return credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_access_token(filename) -> None:\n",
    "    \"\"\"\n",
    "    Writes the new passed in access token into the credentials file.\n",
    "    \"\"\"\n",
    "    # Getting a new access token and writing it into `credentials.txt`\n",
    "    credentials = get_credentials(filename)\n",
    "    \n",
    "    if 'sf_credentials.txt' in filename:\n",
    "        new_token = get_sf_access_token(credentials['client_id'], credentials['client_secret'], credentials['refresh_token'])\n",
    "    elif 'arcgis_credentials.txt' in filename:\n",
    "        new_token = get_arcgis_access_token(credentials['client_id'], credentials['client_secret'])\n",
    "    credentials['access_token'] = new_token\n",
    "    \n",
    "    # Writing new credentials back into `credentials.txt`\n",
    "    with open(filename, 'r+') as f:\n",
    "        json.dump(credentials, f, ensure_ascii=False)\n",
    "    return credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sf_access_token(client_id: str, client_secret: str, refresh_token: str) -> str:\n",
    "    \"\"\"\n",
    "    Gets a new Salesforce access token.\n",
    "    \"\"\"\n",
    "    token_url = get_http('/services/oauth2/token')\n",
    "    payload='client_id={}&client_secret={}&redirect_uri=https%3A%2F%2Fjwt.ms&grant_type=refresh_token&refresh_token={}'.format(client_id, client_secret, refresh_token)\n",
    "    headers = {\n",
    "      'Content-Type': 'application/x-www-form-urlencoded',\n",
    "      'Cookie': 'BrowserId=IoTFrthNEeuXEXtWwwGMWA; CookieConsentPolicy=0:0'\n",
    "    }\n",
    "    response = requests.request(\"POST\", token_url, headers=headers, data=payload)\n",
    "    return response.json()['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_req(data) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataframe from the passed in data from a former API request.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for r in data['records']:\n",
    "        # Converts multi-level dict into a single-level and removes 'attributes' keys.\n",
    "        converted = flatten(remove_a_key(r, 'attributes'))\n",
    "        records.append(converted)\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request_and_transform(endpoint, full_url=True, full_data=False):\n",
    "    \"\"\"\n",
    "    Makes the request to Salesforce for the given endpoint.\n",
    "    Can return all the objects or a subset given from Salesforce.\n",
    "    \"\"\"\n",
    "    # Getting credentials\n",
    "    credentials = get_credentials('../credentials/sf_credentials.txt')\n",
    "    \n",
    "    payload={}\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json',\n",
    "      'Authorization': 'Bearer {}'.format(credentials['access_token']),\n",
    "      'Cookie': 'BrowserId=IoTFrthNEeuXEXtWwwGMWA; CookieConsentPolicy=0:0'\n",
    "    }\n",
    "\n",
    "    # Making the request\n",
    "    url = endpoint if full_url else get_http(endpoint)\n",
    "    res = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    data = res.json()\n",
    "    \n",
    "    # Checking for error messages\n",
    "    if isinstance(data, list):\n",
    "        if 'errorCode' in data[0].keys():\n",
    "            print(\"HTTP Request Access Token Error:\", data[0]['errorCode'])\n",
    "            print(\"Trying to refresh access token...\")\n",
    "            \n",
    "            # Refreshing access token in credentials\n",
    "            refresh_access_token('../credentials/sf_credentials.txt')\n",
    "            \n",
    "            print(\"Refreshed access token. Re-trying request.\")\n",
    "            \n",
    "            # Trying request again with new access token.\n",
    "            return make_request_and_transform(endpoint, full_url, full_data)\n",
    "        \n",
    "    # Formatting data\n",
    "    df = create_df_from_req(data)\n",
    "\n",
    "    # Pulling all the data from Salesforce if requested.\n",
    "    if full_data:\n",
    "        while not data['done']:\n",
    "            url = get_http(data['nextRecordsUrl'])\n",
    "            res = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "            data = res.json()\n",
    "            new_df = create_df_from_req(data)\n",
    "            df = pd.concat([df, new_df], ignore_index=True)\n",
    "            try:\n",
    "                print(\"Finished batch request! Currently on row {}\".format(data['nextRecordsUrl'].split('-')[-1]))\n",
    "            except KeyError:\n",
    "                continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_soql(soql_query: str, full_data: bool=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gets the data into a Pandas DataFrame from the given SOQL query.\n",
    "    'full_data' determines if all of the objects are retrieved or not.\n",
    "    \"\"\"\n",
    "    return make_request_and_transform(get_http(get_endpoint(soql_to_python(soql_query))), full_data=full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting SOQL statements from Salesforce workbench\n",
    "awards_soql = 'SELECT Account__r.BillingStreet,Account__r.BillingPostalCode,Account__r.BillingCity,Account__r.BillingState,Account__r.Name,Award_Amount__c,Contract_Award_ID__c,DBE__c,MBE__c,WBE__c,Opportunity__r.Id,Opportunity__r.Name FROM Award__c WHERE Opportunity__r.Active__c = true'\n",
    "opp_naics_soql = 'SELECT Opportunity__r.Id,Opportunity__r.Account.Name,NAICS_Code__r.Name,NAICS_Code__r.NAICS_Description__c,Opportunity__r.Category__c,Opportunity__r.Bid_Due__c,Opportunity__r.Bid_Post__c FROM NAICS_Opportunity__c WHERE Active_YN__c = 1 AND Opportunity__r.Bid_Due__c > 2016-07-01T00:00:00.000Z'\n",
    "# acc_naics_soql = 'SELECT Account__c,NAICS_Code__r.Name FROM NAICS_Account__c WHERE Active__c = true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request Access Token Error: INVALID_SESSION_ID\n",
      "Trying to refresh access token...\n",
      "Refreshed access token. Re-trying request.\n",
      "Finished batch request! Currently on row 4000\n",
      "Finished batch request! Currently on row 6000\n",
      "Finished batch request! Currently on row 8000\n",
      "Finished batch request! Currently on row 10000\n",
      "Finished batch request! Currently on row 12000\n",
      "Finished batch request! Currently on row 14000\n",
      "Finished batch request! Currently on row 16000\n",
      "Finished batch request! Currently on row 18000\n",
      "Finished batch request! Currently on row 20000\n",
      "Finished batch request! Currently on row 22000\n",
      "Finished batch request! Currently on row 24000\n",
      "Finished batch request! Currently on row 4000\n",
      "Finished batch request! Currently on row 6000\n",
      "Finished batch request! Currently on row 8000\n",
      "Finished batch request! Currently on row 10000\n",
      "Finished batch request! Currently on row 12000\n",
      "Finished batch request! Currently on row 14000\n",
      "Finished batch request! Currently on row 16000\n",
      "Finished batch request! Currently on row 18000\n",
      "Finished batch request! Currently on row 20000\n",
      "Finished batch request! Currently on row 22000\n",
      "Finished batch request! Currently on row 24000\n",
      "Finished batch request! Currently on row 26000\n",
      "Finished batch request! Currently on row 28000\n",
      "Finished batch request! Currently on row 30000\n",
      "Finished batch request! Currently on row 32000\n",
      "Finished batch request! Currently on row 34000\n",
      "Finished batch request! Currently on row 36000\n",
      "Finished batch request! Currently on row 38000\n",
      "Finished batch request! Currently on row 40000\n",
      "Finished batch request! Currently on row 42000\n",
      "Finished batch request! Currently on row 44000\n",
      "Finished batch request! Currently on row 46000\n",
      "Finished batch request! Currently on row 48000\n"
     ]
    }
   ],
   "source": [
    "awards = get_data_from_soql(awards_soql, full_data=True)\n",
    "opp_naics = get_data_from_soql(opp_naics_soql, full_data=True)\n",
    "# acc_naics = get_data_from_soql(acc_naics_soql, full_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "merged_data = (\n",
    "    awards\n",
    "    .merge(opp_naics, left_on='Opportunity__r.Id', right_on='Opportunity__r.Id')\n",
    "    .rename(columns={'NAICS_Code__r.Name': 'Opportunity_NAICS'})\n",
    "#   These two columns are to check the account's NAICS codes as well-- may be useful for the future?\n",
    "#   Currently, this overmerges data and does not follow the Salesforce report.\n",
    "#     .merge(acc_naics, left_on='Account__c', right_on='Account__c')\n",
    "#     .rename(columns={'NAICS_Code__r.Name': 'Account_NAICS'})\n",
    ")\n",
    "\n",
    "# Removing rows with DWP, LAWA, and POLA data to unskew data\n",
    "all_data = merged_data[~merged_data['Opportunity__r.Account.Name'].isin(['Water & Power', 'Airports, Los Angeles World', 'Harbor Department, Port of Los Angeles'])]\n",
    "all_data.drop(columns=['Opportunity__r.Account'], inplace=True)\n",
    "all_data.head()\n",
    "\n",
    "# Exporting `all_data` to CSV to be used in a different script\n",
    "all_data.to_csv('../data/all_naics_data.csv', index=False)\n",
    "\n",
    "# Removing repeated rows split up by NAICS code by removing NAICS code and dropping duplicates\n",
    "all_amount_data = all_data.drop(columns=['Opportunity_NAICS', 'NAICS_Code__r.NAICS_Description__c']).drop_duplicates()\n",
    "all_amount_data.to_csv('../data/all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_business_enterprise(data):\n",
    "    \"\"\"\n",
    "    Extracts the desired DBE, MBE, WBE information from the dataframe to a CSV to be uploaded to a Google Sheet.\n",
    "    \"\"\"\n",
    "    types = ['DBE__c', 'MBE__c', 'WBE__c']\n",
    "    functions = [\n",
    "        # Getting % of contracts award to DBE, MBE, WBEs (by dollar amount) by group\n",
    "        lambda group_type: lambda group: (group['Award_Amount__c'] * group[group_type]).sum() / group['Award_Amount__c'].sum() * 100,\n",
    "        # Getting % of awarded contracts given to DBE, MBE, WBEs (by number of contracts) by group\n",
    "        lambda group_type: lambda group: group[group_type].sum() / len(group)  * 100,\n",
    "        # Getting the total number of awards given to DBE, MBE, WBE contractors by group\n",
    "        lambda group_type: lambda group: group[group_type].sum(),\n",
    "    ]\n",
    "    \n",
    "    # Creating all the functions to aggregate the data with\n",
    "    all_funcs = [pair[1](pair[0]) for pair in list(itertools.product(types, functions))]\n",
    "    \n",
    "    # Constructing the entire dataframe\n",
    "    total_data = []\n",
    "    for func in all_funcs:\n",
    "        total_data.append(all_data.groupby(['Opportunity_NAICS', 'NAICS_Code__r.NAICS_Description__c']).apply(func))\n",
    "    total_data = pd.concat(total_data, axis=1)\n",
    "    \n",
    "    # Renaming + re-ordering columns\n",
    "    total_data.columns = [\n",
    "        '% Dollars awarded to DBEs',\n",
    "        '% Contracts awarded to DBEs',\n",
    "        'Total Number of Awards Given to DBE Contractors', \n",
    "        '% Dollars awarded to MBEs',\n",
    "        '% Contracts awarded to MBEs',\n",
    "        'Total Number of Awards Given to MBE Contractors', \n",
    "        '% Dollars awarded to WBEs',\n",
    "        '% Contracts awarded to WBEs',\n",
    "        'Total Number of Awards Given to WBE Contractors', \n",
    "    ]\n",
    "    total_data = total_data[[\n",
    "        '% Dollars awarded to DBEs',\n",
    "        '% Dollars awarded to MBEs',\n",
    "        '% Dollars awarded to WBEs',\n",
    "        '% Contracts awarded to DBEs',\n",
    "        '% Contracts awarded to MBEs',\n",
    "        '% Contracts awarded to WBEs',\n",
    "        'Total Number of Awards Given to DBE Contractors', \n",
    "        'Total Number of Awards Given to MBE Contractors', \n",
    "        'Total Number of Awards Given to WBE Contractors',\n",
    "    ]]\n",
    "    \n",
    "    # Formatting data + filling null values.\n",
    "    total_data = (\n",
    "        total_data\n",
    "        .reset_index(drop=False)\n",
    "        .rename(columns={\n",
    "            'NAICS_Code__r.NAICS_Description__c': 'NAICS Industry Name (5-digit)'\n",
    "        })\n",
    "        .fillna('No award amount for this NAICS code.')\n",
    "    )\n",
    "    \n",
    "    return total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_category_counts(df):\n",
    "    \"\"\"\n",
    "    Extracts opportunity category counts for each NAICS code.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df.groupby(['Opportunity_NAICS', 'Opportunity__r.Category__c'])\n",
    "        .count()\n",
    "        .iloc[:,0]\n",
    "        .to_frame()\n",
    "        .rename(columns={df.columns[0]: 'Count'})\n",
    "        .reset_index()\n",
    "        .pivot(index='Opportunity_NAICS', columns='Opportunity__r.Category__c', values='Count')\n",
    "        .fillna(0)\n",
    "        .rename(columns={\n",
    "            'Commodity': 'Commodity Count', \n",
    "            'Construction': 'Construction Count', \n",
    "            'Personal Services': 'Personal Services Count'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_naics_opp_counts(opp_naics_df):\n",
    "    \"\"\"\n",
    "    Takes the NAICS_Opportunity dataframe and gets the total opportunity count by NAICS code.\n",
    "    \"\"\"\n",
    "    filtered_df = opp_naics_df[~opp_naics_df['Opportunity__r.Account.Name'].isin([\n",
    "        'Water & Power', \n",
    "        'Airports, Los Angeles World', \n",
    "        'Harbor Department, Port of Los Angeles'\n",
    "    ])]\n",
    "    return (\n",
    "        filtered_df\n",
    "        .groupby(['NAICS_Code__r.Name'])\n",
    "        .count()\n",
    "        .sort_values(by='Opportunity__r.Id', ascending=False)\n",
    "        .reset_index()\n",
    "        [['NAICS_Code__r.Name', 'Opportunity__r.Id']]\n",
    "        .rename(columns={\n",
    "            'NAICS_Code__r.Name': 'Opportunity_NAICS',\n",
    "            'Opportunity__r.Id': 'Number of Opportunities'\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_sheet(all_data_df, opp_naics_df, to_csv=False, to_sheet=False):\n",
    "    \"\"\"\n",
    "    Converts inputted dataframe into final Google Sheet.\n",
    "    \"\"\"\n",
    "    # Converting and merging dataframes\n",
    "    counts_df = data_to_naics_opp_counts(opp_naics_df)\n",
    "    bus_enterprise_df = data_to_business_enterprise(all_data)\n",
    "    cat_counts_df = data_to_category_counts(all_data)\n",
    "    temp = bus_enterprise_df.merge(cat_counts_df, left_on='Opportunity_NAICS', right_on='Opportunity_NAICS')\n",
    "    final_df = (\n",
    "        temp\n",
    "        .merge(counts_df, left_on='Opportunity_NAICS', right_on='Opportunity_NAICS', how='outer')\n",
    "        .sort_values(by='Number of Opportunities', ascending=False)\n",
    "        .fillna('No award info for NAICS code.')\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    # Adding two columns and organization NAICS columns\n",
    "    final_df['Opportunity_NAICS_2'] = final_df['Opportunity_NAICS'].apply(lambda row: row[:2])\n",
    "    final_df.rename(columns={'Opportunity_NAICS': 'Opportunity_NAICS_5'}, inplace=True)\n",
    "    \n",
    "    # Doing final ordering of columns\n",
    "    begin_col = ['Opportunity_NAICS_2', 'Opportunity_NAICS_5', 'Number of Opportunities']\n",
    "    column_order = begin_col + [col for col in final_df.columns if col not in begin_col]\n",
    "    final_df = final_df[column_order]\n",
    "    \n",
    "    # Removing unwanted rows and only listing rows with 100 opportunities or above\n",
    "    legacy_naics = final_df[final_df['Opportunity_NAICS'] == '999999']\n",
    "    if legacy_naics.shape[0] == 1:\n",
    "        final_df.drop(index=legacy_naics.index, inplace=True)\n",
    "    \n",
    "    final_df = final_df[final_df['Number of Opportunities'] >= 100]\n",
    "    \n",
    "    # Creating CSV if `to_csv` is true\n",
    "    if to_csv:\n",
    "        final_df.to_csv('../data/data_to_sheet.csv', index=False)\n",
    "    \n",
    "    # Export dataframe to sheet if `to_sheet` is true\n",
    "    if to_sheet:\n",
    "        \n",
    "        # Get authorization from `google_credentials.json` file.\n",
    "        gc = pygsheets.authorize(client_secret='../credentials/google_credentials.json')\n",
    "\n",
    "        # Open the sheet (replace 'Testing Stuff' with correct sheet name.)\n",
    "        sh = gc.open('Testing Stuff')\n",
    "\n",
    "        # Select first sheet\n",
    "        wks = sh[0]\n",
    "\n",
    "        # Update the sheet with the dataframe\n",
    "        wks.set_dataframe(final_df,(1,1))\n",
    "    \n",
    "    # Returning final dataset\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adding generated Salesforce data to Google Sheet\n",
    "data = data_to_sheet(all_data, opp_naics, to_csv=False, to_sheet=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
